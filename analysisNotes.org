* 9/12/11
  Can I type faster than I write by hand? We will find out.

** Review of the last homework problem from last time
*** Prove E' = ( E U E')'
    easy version:
    in general we have that (A U B)' = A' U B'
    if x is a limit point of A, it is a limit point of the union.

    Therefore the union of the limit points (A' U B') is a subset of (A U B)'

    harder version:
    if x in (A U B)' then every neighborhood Nr(x) containes some point of A U B distinct
    from x. If we can always take y in A, then

    x in A' -> x in A' U B' .

    suppose that

    exists Nr(x) such that (Nr(x) \ {x} ) intersect A = nullset

    then forall r > 0, we must have (Nr(x) \ {x} ) intersect B /= nullset
    therefore x in B'

    To be in A', we need the neighborhood. Some rs, point in A; others, point in B.

    Application : (E U E')' = E' U E'' = E' U E' = E'

    Part a

    Suppose that x in (E')'. To show: x in E'

    By definition, (write definitions and follow your nose), forall r > 0

    (Nr(x) \ {x} ) intersect E' /= nullset

    choose y in (Nr(x) \ {x} ) \{x} intersect E'

    choose r' > 0 s.t. Nr'(y) subset Nr(x) \ {x}

    so y in E' so there exists z in Nr'(y) with z in E, z /= y.

    Therefore z in Nr(x) \ {x}, which is true for r > 0 -> x in E'.


*** Number 8
    E subset R^2, E open -> E subset E'

    E open -> exists r > 0 with Nr(x) subset E

    for x in E subset R^2, Nr(x) infinite -> for r small enough,
    (Nr(x) \ {x}) intersect E /= nullset

*** Actual lecture connectedness
    for subsets A and B of some metric space X, A and B are separated if

    A intersect (closure B) = nullset and (closure A) intersect B = nullset

**** Example:
     A = (0,1) and B = (1,2) not separated
     A set E subset X is connected if E is not disconnected
    E is disconnected -> E has a disconnection -> E = A U B and A,B separated.

    Equivalently - E is disconnected if E = A (disjoint union) B (write it as
    such, union of two sets minus the intersection)
    where A and B are both (E-open OR E-closed OR A is both E-open and E-closed)

*** Now lets go to R^1.

    Theorem 2.42 - A nonempty subset E subset R1 is connected iff E has the following properties:
    (for a < b)

    1. x in E, y in E, x < z < y -> z in E
    2. E is an interval, i.e. E = one of (-inf, b) (-inf, b], [a,b], (a,b], [a,b), R, etc
3. ???

**** Proof
    Let a = inf E
    Let b = sup E
    proceed to show that one of the cases of (2) is valid.

***** Connectedness proof

      negate both conditions - prove that E in R disconnected iff not 2.42

      (trick - set defined by a property. Negate step by step to show x `notin` A)

      not [(forall x, y in E with x < y) (and forall z in R with x < z < y), then z in E]

      Therefore we need to produce a z such that x < z < y but z `notin` E

      Set Az = E intersect (-inf, z), Bz = E intersect (z, +inf)

      for x in Az, Az /= nullset
      for y in Bz, Bz /= nullset

      z notin E, Az union z union Bz = R

      Note that Az intersect (closure Bz) = nullset, and (closure A) intersect Bz = nullset
      so E is disconnected (as z `notin` E)

      (other direction) assume E disconnected, so E = A (disjoint union) B with A, B
      nonempty and separated. Pick x in A, y in B : WLOG x < y.

      (we will use completeness of the reals)

      define z = sup (A intersect [x,y])
      then z in (closure A)
         (by a previous result, sup f in (closure F) for F nonempty, bounded above, subset of R)

    so z `notin` B as the sets are separated.
    so x \leq z < y

    if z notin A then must have x < z < y (strictness) and we are done.

    If z in A, then z notin (closure B) implies (exists z_1 with z < z_1 < y) and z_1 notin B
       Then x < z_1 < y and z_1 notin B. As z_1 > x, z_1 notin A so z_1 notin E and we are done.

* 9/14/11
** Hints for hw5
   G open, V1 open -> G intersect V1 /= nullset

   G1 open -> V1 intersect G1 = new (??) open

   Choose V2 open, (closure V2) subset V1 intersect G1.

   G2 dense -> G2 intersect V2 /= nullset (it is a subset of G1)

   #17

   Use Baire's theorem
   for some E1, take the real number line and throw out everything that is not
   of the form 0.4... and 0.7... and use uniqueness of decimal expansions (keep
   it closed at each set)
   Hard part - invent suitable notation for dealing with it. The intersection
   should be nonempty, but nowhere dense, but perfect, any point in the
   intersection (neighborhood around it) for fine enough the

   property - always have endpoints (like Cantor) so we have
   perfect/uncountable (strings of 4s and 7s is the same as strings of 1s and
   0s, which is uncountable.)

   # 18
   There exists a perfect set with no rationals (answer! it does exist.)
   so rationals Q intersect [0,1] is countable (as Q is countable)

   call this list r_1, r_2, ...

   create an interval around each and remove them, but leave some space between
   each (irrationals between rationals)


** Upcoming Dates
   HW5 due on Monday (extra credit as well)
   HW6 due on Friday (connectedness)

** Definition : K in X is compact means:
   given any open cover {G_alpha : alpha in A} of K (so K is in the union of
   all G_alpha) there is a finite subcover consisting of a finite collection of
   alphas such that K subset union over alpha of G_alpha

*** Examples:

   K = (0,1) is covered by {(0,3/4),(1/2,1)} (finite cover)

   another cover: (1/n, 1) for n in NN, has no finite subcover.

   Not hard to show not compact just from creating a cover with no finite
   subcover.

   For the homework problem {0} U {1/n}, we can use Heine-Borel, but it is more
   instructive to use the definition.

*** TODO Archimedes Corollary
    all but finitely many something something. Fill this out.

*** Nested interval theorem

    for nullset /= In = [a_n, b_n] superset Im
*** Heine-Borel

    Not closed implies not compact.
    Alternatively, we can say that if K is closed and bounded in R then it is
    compact.

*** Compactness of [0,1]

**** Classic version

     Take [0,1] - it is compact (proof : by contradiction : suppose that there
     exists an open cover of [0,1] {G_alpha} with no finite subcover. Note that
     then {G_alpha} covers [0,1/2] and [1/2,1].

     Step 1: assumption implies that {G_alpha} has a cover of at least one of
     [0,1/2] and [1/2,1] . Therefore we have a finite subcover for each, and
     their union is finite and covers [0,1]: a contradiction.

     Part 2: Pick I1 = one of the two so {G_alpha} has no finite subcover of
     I1.

     Get I1 superset I2 ... superset In - by nested interval theorem -> the
     intersection is nonempty - in fact, it must be a single point, x0, since
     the length of In -> 0 (cannot be two things in the intersection, the
     length between them always decreases)

     but x0 in G_alpha for some alpha. and I subset G_alpha0 since the length
     goes to zero. Therefore there is a finite subcover of In.

     Therefore for n large enough, we have a finite subcover of In after all; a
     contradiction.)

**** Other version - not in our book.

     How do we distinguish between [0,1] intersect Q and [0,1] ? completeness.

     Suppose {G_alpha} is an open cover of [0,1]. Our goal is to find some
     finite subcover. Define a set

     E = {x in [0,1] | {G_alpha} has a finite subcover of [0,x]}

     Check : E /= nullset. We are allowed to take x = 0 in E as 0 in G_alpha0
     (as {G_ALPHA} covers [0,1]) so [0,0] has a finite subcover.

     E is bounded above by 1, so by the Least Upper Bound property for RR,

     x0 = sup E exists, 0 leq x0 leq 1

     Claim : x0 exists and x0 = 1. Then we are done.

     x0 exists -> If x0 = 0 we are done.

         Assume x0 > 0 so x0 in [0,1] -> some G_alpha0prime in {G_alpha} such
         that G_alpha0prime open -> exists delta > 0 s.t.

         N_delta(x_0) = (x0 - delta, x0 + delta) subset of G_alpha0prime

         Then x0 - delta < x0 -> exists s in E s.t. x0 - delta leq s leq x0

         Then {G_alpha} has a finite subcover over [0,s]. Then throw in to that
         union of sets G_alpha0prime which covers [0,x0].

         In conclusion : x0 in E (used t < x0 -> t not an upper bound)

     Part 2: Suppose that x0 /= 1, so x0 < 1.

     x0 in G_alpha0prime and (x0 - s, x0 + s) in G_alpha0prime. For x0 in E
     there exists some union of Gs s.t. their union covers [0,x0] then that
     union with G_alpha0prime is a superset of [0, x + delta] -> 1 in E and 1
     is least upper bound -> {G_alpha} has a finite subcover of [0,1].




* 9/16/11
** 2.16, last problem on HW4
   p in QQ s.t. 2 < p^2 < 3
   E = (-srt(3), -sqrt(2)) U (sqrt(2), sqrt(3)) intersect Q

*** E is closed in Q
    show that E closed in RR, so closed in R intersect QQ -> QQ closed

*** E is bounded
    E is bounded as d(p,0) < sqrt(3)

*** E is not compact in QQ
    since E is not closed in RR, E is not compact in R
    so by Heine-Borel E is not compact in QQ.
**** Directly
     Gn = {(-sqrt(3) + 1/n, sqrt(3))} intersect Q
        = open cover with no finite subcover.

*** E is QQ-open:
    E = [-sqrt(3), -sqrt(2)] U [sqrt(2), sqrt(3)] intersect QQ
    so RR-open intersect QQ -> E is QQ-open

** Hint for next homework - correction
*** for 4,7 problem
    4, 7 decimal expansions
    at each step, end points go away
    when proving perfect : take point in the intersection of the layers, find a
    point in the interval (in the generalized Cantor set)
    Show that we have a fractal thing - same no matter where we start (same
    thing at every scale)
    Fun problem once understood!

*** Announcement - HW6 and Test 1, Friday September 23
    HW not too hard.
    Test - everything up to connectedness (basic topology, sets, neighborhoods,
    completeness)

** Next Chapter - Sequences in Metric Spaces
   We will start in RR and many ideas hold for general metric spaces.
   for metric space (X,d)
   some function NN -> X is called a sequence (n -> pn)
   Say {p_n} = [p_1, p_2, p_3, ...]

*** Fundamental Notion : Convergence.
    Given traditional epsilon:
    limit as n -> inf of p_n = P means
    given epsilon > 0, exists N s.t. n > N -> d(p_n, p) < epsilon

*** Example
    1/n has limit p_n = 0 (by archimedes)
    given epsilon, exists N s.t. if n > N -> 0 < 1/n < epsilon
    which implies d(1/n, 0) < epsilon for n > N

*** Elementary Facts
    Convergence: {p_n} -> P <-> every neighborhood of P contains all but
    finitely many terms {p_n}
    Uniqueness: if {p_n} -> P and {p_n} -> P' then P = P'
    Convergence: {p_n} convergent -> {p_n} bounded.
**** Proof of Uniqueness
     (show the distance between P and P' is less than epsilon, for epsilon > 0)
     We do equality here by exhaustion
     Given epsilon > 0, exists N_1 s.t. n > N_1 -> d(p_n, P) < epsilon/2
     Given epsilon > 0, exists N_2 s.t. n > N_2 -> d(p_n, P') < epsilon/2

     Then by the triangle inequality, for m > max(N_1, N_2) we get
     d(P, P') leq d(P, p_m) + d(p_m, P') < epsilon/2 + epsilon/2
                                         < epsilon
     so 0 leq d(P, P') < epsilon for all epsilon
     implies d(P, P') = 0 -> P = P' (metric space definition)
**** Proof of Convergence
     choose epsilon = 1
     so there is some N_1 s.t. d(p_n, p) < 1 for n geq N
     Let M = max(d(p_1, p), d(p_2, p) ... d(p_n-1, p), 1) < inf
     so d(p_n, p) leq M for all n -> {p_n} bounded.

*** Complex Numbers
    X = CC
    congruent to RR
    x + iy equivalent to (x,y)
    d(x + iy, x' + iy') = sqrt( (x - x')^2 + (y - y')^2)

    Theorem : {s_n}, {t_n} complex, s_n -> s, t_n -> t implies:
    1. s_n + t_n -> s + t
    2. s_n t_n -> s t
    3. For c in CC, c s_n -> c s
    4. If s_n /= 0 and s /= 0 then 1/s_n -> 1/s.
**** Proof of Laundry List
***** 1. | s_n + t_n - s - t| = | (s_n - s) - (t_n - t)|
      \leq | (s_n - s) | + |(t_n - t)| < eps
      \leq | (s_n - s) | + |(t_n - t)| < epsilon/2 + epsilon/2
      and of course individually | (s_n - s) | < epsilon/2, etc, so done
***** 2. s_n t_n -> s t
      | s_n t_n - s t | = | (s_n - s) t_n + s(t_n - t)|
      \leq | (s_n - s) | | t_n | + | s | | (t_n - t) |
      both bounded.

     Others similar.

*** RR^k
    Theorem: in RR^k, X_n = (alpha_(1, n) ... alpha_(E,n)) implies X = vector
    of converged alphas

    Reason: comprable norms. Can generally just interchange them with absolute
    value signs from RR.

    x_n dot y_n -> x dot y.
    book proof : brute force
    elegant proof : Cauchy-Schwarz

    for | xn dot yn - x dot y | =    (xn - x) dot yn + x dot (yn - y) |
                                leq | (xn - x) dot yn | + | x dot (yn - y) |
                                leq | (xn - x) | | yn | + ...
                                all bounded!



* 9/19/11
** Limits
*** Limit Review
    lim over (n -> inf) p_n = p means:
    forall epsilon > 0 exists N in NN s.t. n geq N -> d(p_n,p) < epsilon.

    this is the same as saying that every neighborhood of p contains all but
    finitely many terms of the sequence p_n.

*** Limit Properties
    {p_n} convergent to p -> {p_n} bounded.

    we proved that exists M < inf s.t. d(p_n,p) leq M for all n (bounded)

    Pick any p_o in X. then exists M' s.t. d(p_n, p_o) leq M': (use the
    triangle inequality) Since the distance

    d(p_n, p_o) leq d(p_n, p) + d(p_o, p)
                leq M + d(p, p_o) = M'

*** Connection between sequential limits and limit points
    If E subset X, p in E -> {p_n} subset E, lim p_n = p.
**** Limit Points and Limits
     Suppose that {p_n} is a sequence, lim p_n = p.

     set E = Ran {p_n} = {p_1, p_2, ...} subset X

     is p in E' ?
     Suppose that p_n = p for all n. Then lim p_n = p but p notin (Ran {p_n})'

     If Ran {p_n} is infinite and lim p_n = p, then p in (Ran {p_n})'.

     (limit points and limits of sequences do not always line up in an
     intuitive manner)
*** Subsequences of {p_n}
    Suppose the subsequences of {p_n} subset X, a metric space. Consider some
    sequence k -> n_k of positive integers (so a function :: NN -> NN) which
    is strictly increasing. : n_1 < n_2 < ... etc. Thus necessarily n_k geq k.

    Perhaps lim (n -> inf) p_n does not exist, but lim (k -> inf) p_(n_k) does
    exist for some subsequences {p_(n_k)}.
**** Example
     x_n = (-1)^n : fails for n = 1,2,3... but converges to 1 for n = 2,4,6,...
     (a good example of bounded, but not convergent)
**** Fact : {p_n} -> p iff every subsequence converges to p
***** Proof (<-) trivial. Every subsequences converges means that p_n -> p.

      (->) need some definitions. p_n -> p means that we can use the epsilon
      definition. So pick some {p_(n_k)}, any subsequence.

      k geq N -> n_k geq N, so d(p_(n_k), p) < epsilon
      which is equivalent to lim (k -> inf) p_(n_k) = p.

***** Usefulness
      This is a useful theorem. Why:

      Theorem 3.6 - if {p_n} some sequence in a compact set (in a metric space)
      then there exists some {p_(n_k)} that converges to some p in X.

****** Proof
       Let E = range {p_n}, if E is finite, we can choose a constant subsequence
       and therefore it is convergent.

       Suppose E is infinite. X compact -> E' /= nullset (earlier theorem).
       Pick some x in E'.  Construct {p_(n_k)} subset E s.t. lim (k -> inf)
       {p_(n_k)} = x.

       step 1 : choose n_1 s.t. p_(n_1) /= x and d(p_n, x) leq 1. Choose each n
       s.t. n_1 < n_2 < ... where

       d({p_(n_k)}, p) < 1/k . Find n_(k+1) > n_k s.t.
       d({p_(n_(k + 1))}, p) < 1 / (k+1).

       This is possible since there are infinitely many p_ns in N_(1/(k+1))(p).

       Now choose some K(epsilon) s.t. 1/K(epsilon) < epsilon (by archimedes)

*** TODO Every bounded sequence in RR^k contains a convergent subsequence.
       so {x_n} bounded -> {x_n} subset of a k-cell I, which is compact by
       Heine-Borel. Rest of proof hard to read

** Theorem 3.9

   Given some {p_n}, (if some function n = p_n) then it is a subset of a metric
   space X.

   Let E* = {p in X : exists subsequence {p_(n_k)} s.t. lim (k -> inf) p_n_k ->
   p} (sequential limit set)

   Then E* is closed. This is similar to the (E')' subset E'.
*** Proof (different from book version)
    suppose q is the limit point of (E*)' (to show: q in E*).

    (i.e. we must cook up some n_1 < n_2 < ... s.t. lim (k -> inf) p_n_k = q)

    step 1: given q, there is some p1* in E* s.t. d(p1*, q) < 1. Therefore as
    p1* in E* we can say that p1* = lim (i -> inf) p_(n_i), where {p_(n_i)} is
    some subsequence of {p_n}. Then

    exists k_1 in {n_1, n_2, ...} s.t. d(p^(1)_(k_1), p1*) < 1 - d(p1*, q) > 0

    this gives us p_(k_1) = p^(1)_(k_1).

    Note that d(p^(1)_(k), q) leq d(p^(1)_(k_1) p1*) + d(p1*, q) < 1.

    INDUCTIVE STEP - assume that we have k_1 < k_2 < ... < k_n with distance
    d(p_(k_j), q) < 1/j. Choose k_(n+1) as follows:

    choose p*_(n+1) in E* with d(p^*_(n+1), q) < 1 / (n + 1)

    then p*_(n+1) in E* -> p*_(n+1) = lim (k -> inf) p^(n+1)_k

    so {p^(n + 1)_k} subset {p_n}

    choose p_n_(k + 1) in {p^(n + 1)_k}, n_(k + 1) > n_k.

    so d(p_n_(k+1), p*_(n+1)) < 1/(n+1) - d(p^*_(n+1), q) ->


* 9/21/11
** Review of homework 5
*** Problem 17
    Uncountable - show that it is perfect or use Cantor diagonalization.
    (as nonempty perfect -> uncountable)

    Dense : contains no intervals, so 'nowhere dense'

    compact : Yes, by decimal expansions.

    x in Ec -> (x - eps, x + eps) subset Ec

**** Countable

     E = infinite intersection of En, where
     En = disjoint union of 2^n closed intervals, length 1/10^n

     Yet another way : x = 0.alpha1 alpha2 alpha3 etc, 4 or 7.  Pick n
     s.t. 1/10^n < delta.

     Let x' = 0. phi1 phi2 etc where if k /= n then phi_k = alpha_k else flip to
     other digit.

     Then x' in E, x' /= x, so uncountable.

*** Problem 18
    Is there a nonempty perfect set with no rationals? Yes!

    we went over a sketch in class - here is Sara's version.

    Know that QQ is countable, = {r1, r2, r3, ...} and use 'a touch of measure
    theory'

    Let epsilon > 0, let In = (r_n - epsilon/(2*2^n), r_n + epsilon/(2*2^n))
    and use these to 'cover up' intervals.

    so the sum of all In is epsilon.

    E = RR \ union of In - uncountable, closed (uncountable because the
    measure, epsilon, is positive)

    (now show that it is perfect - no isolated points)
    so delete countably many isolated points (number of isolated points must be
    countable because each has some interval around it; injection of isolated
    points in to rationals) so we still have an uncountable set and i is
    perfect.

*** Problem on Baire's Theorem
    Baire's Theorem - if Fn closed and nowhere dense subset of RR^k then

                                union Fn /= RR^k.

    Important to have RR^k - if we used QQ we could write QQ as a countable
    union of sets (each set has exactly one point of QQ).

    Therefore we expect our proof of a special case to use some special feature
    of RR^k to work (completeness).

** Extra Credit Answers

   Was fun. Let (X,d) be a metric space then the following are equivalent:

   1. every open cover has a finite subcover (definition of compactness)

   2. Every collection of closed sets {F_alpha : alpha in A}  with the FIP has
      the property intersection of F_alpha /= nullset

   3. Every infinite subset has a limit point.

   4. (next chapter!) every sequence has a convergent subsequence.

   Things related to these may be on the test.

*** harder part: 3 -> 1

    break up in to three pieces.

    X separable -> X has a countable base (#23)

    V_alpha, alpha in A

    base means that for each G open, x in G, there is a V_alpha with x in
    V_alpha (so G is the union of V_alpha s)

**** Solution
     V = { N_q(s) : s in S, q in QQ+} (S is the separable set)
     V is indexed by S x QQ+, so it is countable.

     triangle inequality 'tap dance' follows

     Let x in G, G open. Choose r in QQ+, N_r(x) subset G.
     Choose s in S with s in N_(r/2)(x). Then x in N_(r/2)(x) and y in the same
     neighborhood implies thad d(y,x) leq d(y,s) + d(s,x) < r

     so x in N_(r/2)(s) subset G : this gives us our V!

*** Number 24
    X - metric space such that every infinite subset has a limit point -> X is
    separable.

**** Proof
     Fix delta > 0. Pick x1 in X.

     having chosen x1, ... , xj in X choose (if possible) x_j+1 in X

     with d(x_j+1, x_k) geq delta for k = 1 .. j. Then: if this is always
     possible we get an infinite set s.t. E = {x1, x2, ...} s.t. d(x, x') geq
     delta for x, x' in E, x /= E'.

     If p = limit point of E, then the distance d(x,x') leq d(x,p) + d(p,x')
     leq delta for any distinct x, x' in E intersect N(p) -> a
     contradiction. Therefore this stops as X subset N(x_j^delta)

     so for each delta, we repeat this and get finitely many per delta.

     This notation is really bad. Can we improve it?

     set x^(n)_j = x_j^(1/n) for n in NN delta = 1 / n

     then let S = {x_j^(n) : j = 1 .. K(1/n), n in NN} which is a countable
     set. Details : more triangle inequality.

*** Number 26
    Let X be a metric space where every infinite subset has a limit
    point. Prove that X is compact.

**** Proof

     #24 -> X is separable.
     #23 -> X has a countable base.

     Let G_alpha, alpha in A be any open cover of X. Then:
     1. {G_alpha} has a countable subcover (as we have a countable base) How
        does this work (namely, countable base -> countable subcover)? Each x
        in X is in some G_alpha, so there exists some V_n(x, alpha) in the
        countable base with x in V_n(x, alpha) and V_n(x, alpha) subset
        G_alpha.

        Define n -> alpha(n) by G_alpha(n) as any choice of G_alpha where V_n
        subset G_alpha(n) (if no such n, leave alpha(n) undefined)

        Then what we did above implies that X subset {G_alpha(n), n in NN} so a
        subcover.

        If {G_alpha(n)} has no finite subcover then

        F_n = (union G_alpha(j))^c /= nullset (cannot cover everything with
        finite set)

        and the intersection of all F_ns is the nullset.

        By hypothesis, every set has a limit point, so x in E' exists, so x is
        in the intersection of all F_n -> a contradiction.

** Test mechanics
   mostly definitions, things we have seen before (easier than the extra
   credit)

   Do all the homework, get experience, know the 'lay of the land' of analysis.


* 9/26/11
** Test news
   reverse bell curve: 5 below 80, 5 above 90, 2 inbetween.

** Review of connectedness HW

*** Problem 20
    pick the 'eyeglasses' in RR^2 - circle at -1, circle at 1:
    connected, but E^' disconnected.
    the definition of connected is too hard to work with - use disconnected.
**** Show that (closure E) disconnected -> E disconnected.
     Say that closure E has a separation, or
     (closure E) = A disjoint union B

     so (closure A) intersect B = nullset.
     so A intersect (closure B) = nullset.

     THen show that E = (A intersect E) disjoint union (B intersect E) is a
     disconnection of E.

     The nontrivial part is to show A intersect E /= nullset.
*** Problem 19
**** Show A, B closed , A intersect B = nullset -> (closure A) intersect B = nullset
     (and that (closure B) intersect A = nullset)

     make it easier - E disconnected <-> E is a disjoint union of A and B.
     Therefore for A and B disjoint, A = E (where E is open and E is closed)
**** Show that A = (fix p) {q | d(p,q) < delta } = open on X.
     and that B = { q | d(p,q) > delta} open on X.

     E = disjoint union of A and B -> E disconnected.

     A and B clearly disjoint.
**** X has two points (at least), X disconnected -> X uncountable.
     For each alpha, 0 < alpha < d(p,q), if there is no q_alpha s.t.

     d(p,q_alpha) = alpha -> X disconnected (we know that)

     Therefore for each alpha choose some q_alpha in X with s.t. d(p,q_alpha) =
     alpha.

     (show that q_alpha is one-to-one) cannot have two values for distance.
     we can do a similar trick to show that q_alpha works for
     alpha in some [0, d(p,q)] - an uncountable interval.

** Chapter 3 - more sequences.
*** Limits
    lim (n -> inf) p_n = p implies :

    forall epsilon > 0, exists N(epsilon) in NN s.t.
    if n geq N then d(p_n,p) < epsilon.
    lim s_n = s means : | s_n - s | < epsilon

*** Subsequences
    Function k in NN, n_k in NN
    with n_1 < n_2 < ... < n_k_1 < ...
    subsequences still converge to the original limit.

*** Characterizations of compact metric spaces
    if X is a metric space, then the following are equivalent:
    1. X is compact.
    2. F_n closed then {F_n} has the finite intersection property (intersection
       of all nonempty)
    3. Every countably infinite subset of X has a limit point in X.
    4. Every sequence P_n contained in X has a convergent subsequence.

**** Proving it
     1 -> 2 : extra credit problem: an open cover may be 'collapsed' to a
     countable open cover. Then "De'Morganize" the contrapositive.
     (compact and countably compact are the same for metric spaces)
     2 -> 3 : straightforward.
     3 -> 1 : extra credit problem from Ch2.

***** 3 <-> 4
      Create the list E = {p_1, p_2, ...} = countably infinite subset of
      X. View this as a sequence. Identify a limit point of E = limit point of
      the subsequence of {p_n}

      then showing 3 -> 4 is trivial by boundedness.

*** Corollaries to the Laundry List
    Infinite subsets E of RR^k have limit points (since E subset closed k-cell,
    which is compact)

    Bounded sequences have convergent subsequences.

    (these imply completeness)

*** Theorem 3.7 - Given a sequence {p_n} in some metric space X

    Let E = subsequential limit set, or
    E = { q | exists {n_k} s.t. q = lim (k -> inf) p_(n_k) }
    then E is closed (limit points of subsequential limits themselves
    subsequential limits)
**** Proof
     Two-step tango - use triangle inequality. In other news, Cameron's parents
     are professional ballroom dancers.

*** Cauchy Sequences
    A sequence {p_n} in a metric space X is cauchy <-> given epsilon > 0,
    exists N(epsilon) in NN s.t. m,n geq N -> d(p_n,p_m) < epsilon
    (the terms get close to each other)

    Result: Theorem 3.11

*** Theorem 3.11 : {p_n} convergent -> {p_n} cauchy
    for some compact metric space the converse is also true.
    X subset RR^k also implies the converse.

    suggests a definition : X is complete if its cauchy sequences converge.

*** Corollary to 3.11
    X is compact, or X = RR^k -> X complete.
    (however the reverse is not true. Complete does not imply compact.)
**** Proof
     part one - easy - use a delta epsilon arguement.
     Say lim (n -> inf) p_n = p, so we know the usual things about epsilon and
     N(epsilon).
     then for n, m geq N(epsilon/2) we get
     d(p_n,p_m) leq d(p, p_n) + d(p, p_m) leq epsilon/2 + epsilon/2 leq epsilon

     part two - {p_n} cauchy -> {p_n} convergent

     {p_n} cauchy -> {p_n} bounded. Choose N = N(1). Then n geq N ->
     d(p_m, p_N) < 1. Let M = max(d(p_1,p_N), d(p_2, p_N), ... , d(p_N-1, p_N))

     Specialize : pick X = RR^k. By Heine-Borel we get that closed k-cells are
     compact. Therefore for p_n bounded -> {p_n} subset J = closed k-cell in
     RR^k. By Heine-Borel J is compact. Therefore this implies that {p_n} has a
     convergent subsequence with a limit in J.

     The guts chunk (X = RR^k : {p_n} cauchy -> {p_n} convergent)

     Say that {p_n} is cauchy in a compact metric space X.
     X compact -> exists {p_n_k} subsequence with limit p, p in X.
     Claim : lim p_n = p.
     (show that if the subsequence coverges to p, everything converges to p)
     (different from Rudin : Rudin reproves that 2 -> 3 from earlier. Not
     optimal.)
     (we will use 4 - every sequence has a convergent subsequence.)

     Let epsilon > 0 . Then choose N_1 s.t. k geq N_1 -> d(p_n_k, p) <
     epsilon/2.

     Similarly, choose N_2 s.t. n, m geq N_2 -> d(p_n, p_m) < epsilon/2.

     Suppose that n > N_2. Then choose k_0 s.t. n_k_0 >  N_2 and k0 > N1

     then d(p_n, p) leq d(p_n, p_k0) + d(p_nk0, p)
                    =   epsilon/2 + epsilon/2


* 9/28/11
** New homework due on Monday (check email for PDF)
   page 78, #5 and handout, page 7.1

** Review
   for some metric space X, the following are equivalent:
   1. X compact
   2. {F_n} bounded with the finite intersection property
   2. Countably infinite subsets have a limit point.
   2. Any sequence has a convergent subsequence.

** Theorem 3.1
   X compact metric space and
   {p_n} cauchy -> {p_n} convergent.

   A more efficient proof - start with 4 and show that Cauchy sequences
   converge.

*** Proof
    Lemma required - show that if {p_n_k} -> p then {p_n} -> p (#20)

    Variation on #20:
    Suppose that {p_n} is a sequence and contained in the metric space. Every
    subsequence {p_n_k} has, in turn, a subsequence {p_n_k_j} with limit as (j
    -> inf) p_n_k_j = p (limit independent of choice of subsequence). Then as a
    subsequence converges the whole sequence converges.

    This is used in the presence of compactness (we know that any sequence has
    a convergent subsequence). If we can show that two subsequences converge to
    the same thing we are okay.

    Therefore, for reformulation, use the contrapositive:

    not (lim p_n = p) implies exists {p_n_k} such that no subsequence {p_n_k_j}
    can converge to p.

    (therefore cook up a subsequence such that all subsequences cannot converge
    to p)

    a.k.a find p_n_k s.t. d(p_n_k,p) geq epsilon (all terms stay away from p,
    so subsequences cannot converge to p)
**** Example
     (-1)^n is a good example of lim (n -> inf) (-1)^n = 1. We can pick the
     subsequence (-1)^odd, which is never one, so all of its subsequences are
     never 1 as well.

** Limits
   Limits do not always exist! Take X = RR. We have seen that cauchy ->
   bounded, but the converse fails in general (remember (-1)^n, nice and
   bounded). However, bounded and 'something else' -> cauchy -> convergence (as
   RR is complete).

   This something else is 'monotonic'.

*** Monotone Convergence Theorem
    Let {x_n} subset RR. Then if x_n leq x_(n+1) for all n in NN, we say it is
    monotonically increasing. If {x_n} is bounded as well then it is
    convergent.
**** Proof, for RR
     Our candidate for the limit is the sup. Now we just show that this is the
     case.
     Given epsilon > 0, there is N such that n geq N implies | s_n - s | <
     epsilon, so

     -epsilon < s_n - s < epsilon

     by definition of the sup, sup - epsilon is not an upper bound, so

     for some N in NN, s - epsilon < s_NN.

     For n geq N, s - epsilon < s_N leq s_n leq s < s + epsilon Done!

     (this is valid by completeness of RR)

**** Inconvenience and lim sup
     Given {s_n}, lim s_n may not exist. That would be a problem.

     Fix it by: lim sup s_n and over{RR} = RR U {inf, -inf}
     Don't subtract inf and -inf, or multiply them by zero. Instead 'throw up
     your hands' (this isn't really a field)

     Expand the definition of lim (n -> inf) s_n to include inf and -inf.

     lim (n -> inf) = inf means that given M < inf there exists N in NN such
     that n geq N -> M < s_n.

     lim (n -> inf) = -inf means that given M in RR then N in NN exists such
     that n geq N implies s_n < -M.

*** Refined Bolzano-Weirstrass
    Any sequence {s_n} contained in bar{RR} has a convergent subsequence.
    (we no longer need boundedness, if we are in bar{RR})
    (most of our sequences are real valued, but can converge to +/- inf)

    bar{RR} is a metric space by d(s,t) = | artcan s - arctan t |
    where arctan inf  = pi / 2
          arctan -inf = -pi / 2

**** Consequences
     So let {s_n} be a subsequence in RR (recall that we are allowed now to
     converge to things in bar{RR}). Then

     E = subsequential limits of {s_n} in bar{RR}

     is nonempty by the refined Bolzano-Weirstrass.

     Refine the least upper bound property for some S subset bar{RR}. in
     particular, S subset RR has a least upper bound in bar{RR}

     (the upper bound on the empty set is -inf. Weird.)

** Lim Sup
   {s_n} in RR, define bar{lim} (also known as lim sup) as

   sup E({s_n}), where E is the set of subsequential limits of its
   arguements.

   nice - this always exists.

   Homework problem - show that lim sup s_n + t_n leq lim sup s_n + lim sup
   t_n (provided that the sum is not inf - inf; assume one is finite).

   add part b : give an example where it is a strict inequality.

   Where does this notation come from? 'Supremum of the subsequential limit
   set' of this sequence.

   equivalency theorem : lim sup s_n = lim (n -> inf) (sup (k geq n) {s_k})

   also called the sequence of the tail. As n increases, the number of elements
   in {s_k} decreases, so we expect the sup to not 'blow up'.

*** Proof
    Suppose x in E = (subsequential limit set of {s_n}), so

    x = limit (j -> inf) s_n_j for some s_n_j in {s_n}.

    We will do the finite case (do the infinite case for practice).

    choose some epsilon > 0, so x - epsilon < s_n_k (n_k strictly increasing)
    for k geq K(epsilon).

    Therefore x - epsilon < sup (k geq n) s_k for all n.

    therefore this implies that for x = any element of E, x - epsilon leq inf
    (n -> inf) (sup (k geq n) s_k) which implies that

    x leq inf sup s_k

    which implies that x leq upper bound for E, so the sup of E leq inf sup
    s_k.

    next time : show inf sup in E.
**** TODO : Infinite case

* 9/30/11
** Homework due on Wednesday
   3,4,16 78-81

*** Homework hints 3.3

    Monoconte convergence theorem, define {s_n} by s_1 specified, s_n+1 =
    f(s_n)

    and s_n bounded and monotonically decreasing -> convergent.

*** 3.4
    Recursively defined lim sup condition

    or rather, s_n defined recursively. Find the lim sup

    strategy : show that the limit of s_2m = s_even (exists)
    and limit of s_(2m-1) = s_odd (exists)
    therefore the limit of the infimum, we get to subsequential limits (s_even
    and s_odd)

    so lim s_n overbar = max (s_e, s_o)
    so lim s_n underbar = min (s_e, s_o)

*** Homework hints 3.16 - Newton's method for x^2 = alpha.

    Everyone loves Newton's method!
    instead of the picture we use monotone convergence theorem. Show that the
    subsequence converges, or something.

*** More hints

    not sure what problem these go with. Oh well.

    for f :: RR -> RR
    if f is increasing then x < y -> x(x) < f(y)
    so s_2 < s_1 -> s_n+1 < s_n for all n

** More Lim Sup and Lim Inf
*** Lim Sup

    overbar lim (m -> inf) s_n := (subsequential limit set for s_n)
                                = sup E({s_n})
                                = lim (n -> inf) (sup, k geq n) of {s_k}
    We can split them apart! Compose it with two more 'fundamental' operations
    (lim and sup)

    last time - showed that x in s_n -> x leq infimum (sup {s_k}, k geq n)
    call this the Rudin definition. Then

    overbar lim s_n leq lim (sup {s_k})

    how about the reverse? Suffices to show that

    lim (n -> inf) sup (k geq n) s_k is in E({s_n}) (so of course it is less
    than or equal to the sup)

    Say that L := lim (n -> inf) sup (k geq n) s_k

    Then this guy (sup k geq n s_k) is a sequence; call it t_n
    Choose some n_1 with L leq t_n_1 leq  L + 1, so choose k_1 > n_1 with

    L - 1 < s_k+1 leq t_n1 < L + 1

    as t_n1 was a supremum larger than L, so find something less than L.

    Then:
    L - 1/i < s_k_i < L + 1/i

    so choose some n_j+1 > k_1 with L leq t_j < L + 1/(i+1)

    we get layers of subscripts!

    L - 1/(j+1) < s_k_(j+1) leq t_j

    In this way we can get some {s_k_j} such that

    L - 1/j < S_k_j < L + 1/j implies s_k_j -> L.

    Another way to look at the problem - 3.17 - real valued sequences

    {s_n} subset RR (could also use bar(RR))

    Let s* = lim sup of s_n. Then

    s* is a subsequential limit and we can skip to the last few steps.

    If x > s* then exists N s.t. n geq n implies s_n < x. Therefore we have a
    subsequential limit.

    Therefore s* = lim sup s_n, which means :

    a. forall epsilon, exists infinitely many ns with s* - epsilon < s_n, so
    there is a subsequence whose limit is greater than s* - epsilon, so there
    are subsequences with limits greater than s*,


    b. Exists N(epsilon) so that s_n < s* + epsilon for all n geq N(epsilon).
    No matter how far you go, you could still go farther. This tears apart
    sequences.

**** Proof of b
     We don't really need to prove this. There is a subsequence that goes to
     s*.

     Uniqueness : two distinct such numbers p and q satisfying (a,b) then say x
     (say that p < x < q) then all s_n with n geq N have s_n < x and infinitely
     many s_ns including some bigger than N have s_n > x -> contradiction. This
     determines s* uniquely.

** similarly:
   lim inf {s_n} = inf E({s_n}) = lim (n -> inf) infimum (k geq n) {s_k}
                                          sup over n inf (k geq n) {s_k}

**** Proof by 'erasure' - same as before.
     exists sme N(epsilon) such that for all n past a certain point,
     s_n > s* - epsilon for n geq N.

*** Examples

    s_n = (-1)^n n -> the subsequential limit set is inf, -inf
    therefore lim sup is inf, lim inf is -inf

    s_n = r_n where r_1,r_2 is an enumeration of QQ
    so E({s_n}) = bar(RR) (we can get anything we please out of it.)

    s_n = (-1)^n / (1 + 1/n)

    therefore E({s_n}) = {1, -1} (we can approach both.)

    How about something more interesting - recursive formula

    #4 on page 78 - good luck.

** Relation with lim s_n = s

   means that forall epsilon > 0, exists N(epsilon) s.t. n geq N(epsilon)
   implies s - epsilon < s_n < s + epsilon.

   (if this is satisfied, then lim sup = lim inf (it is iff))

   always true : lim inf s_n = inf E ({s_n}) leq sup E({s_n}) leq lim sup.

*** sneaky proofs - showing that certain limits exist.

    to show s_n convergent (to something) it suffices to show that

    lim sup of s_n leq lim inf s_n.

    (as lim sup geq lim inf, so we have sandwiching, so the limit exists)

    this is a useful trick! We will need it.

** Advanced Calculus Theorem, 4225 equivalent

   lim t_n exists, equals t, s_n leq t_n -> lim s_n leq t.

   better formulation - for s_n leq t_n forall n geq N (some N) then

   a. lim inf s_n leq lim inf t_n

   b. lim sup s_n leq lim sup t_n.

**** Proof
     (b) via lim sup of s_n = sup ({s_n})
     let x in E({s_n}) so x = lim s_n_k

     by the limit theorem : x leq lim t_n_k exists.
     pick some {t_n_j_k} subset {t_n_k} with
     t_n_j_k exists and the limit is t. So this is a subsequence of t_n, and
     therefore t in E({s_n}), t leq lim sup of t_n.

     but also : lim s_n_j_k = s.

     also know that s_n_k_j leq t_n_k_j, so by the advanced calculus theorem,
     we have that x leq t leq lim sup of t_n forall x in E({s_n}) that
     lim sup s_n leq lim sup t_n

* 10/03/11
** Sophomore Calculus level maths
*** special sequences
    p > 0 -> lim 1/n^p = 0
    p > 0 -> lim nth root of p = 1
    lim nth root of n = 1
    p > 0, alpha real -> lim n^alpha / (1 + p)^n = 0
    abs(x) < 1 -> lim x^n = 0

*** Proofs
    1. take the logarithm:
       ln n^(-p) = -p ln n -> - inf
       which implies the limit is exp(-inf) = 0
    2. again, take the logarithm:
       ln nth root of p = 1/n ln p -> 0 so exp(0) = 1.
    3. ln n root n = ln n / n approx 1/n / 1 -> 0, so we get exp(0) = 1.
    4. n^alpha = exp(alpha ln n)
       goes to 0 for alpha < 0
       goes to 1 for alpha = 0
       goes to inf for alpha > 0
    5. abs(x^n) = abs(x)^n suffices to assume 0 < x < 1
       ln x^n = n ln x -> - inf

*** We are agnostics and don't know how to do any of that.
    What do we know? Combinatorics, binomial theorem, not calculus.

*** Proving stuff with just the binomial theorem
    3224 proof, epsilons and Ns

    1. take n > (1/epsilon)^(1/p). Then 1/n^p < epsilon
       for n > N(epsilon) = (1/epsilon)^(1/p)
    2. If p > 1, let x_n = (nth root of p) - 1. Then
       (binomial theorem) 1 + n * x_n leq (1 + x_n)^n = p
       (keep only the first two terms: this part is an art.)
       Therefore 0 < x_n leq (p - 1)/n
       by the squeeze theorem x_n must go to zero, as it is bounded by
       sequences that converge to zero.

       some more cases:
       p = 1 : trivial (everything zero)
       p < 1 : take the reciprocals.
       (nth root of p) = 1 / (nth root of 1/p) and 1/p > 1.

    3. Put x_n = (nth root of n) - 1 geq 0
       so again by the binomial theorem we have
       n = (1 + x_n)^n geq n(n-1)/2 x_n^2 geq (n-1)x_n^2 valid for n geq 2.

       a clearer way : 2n geq n(n-1)x_n^2 or 2/(n-1) geq x_n^2

       (by 1. x_n leq (sqrt 2 / (n-1)), which goes to zero)

       therefore we are squeezed again as x_n leq something that goes to zero


    4. p > 0 and alpha real : pick integer k, k > alpha, k > 0. For n > 2k,

       (1 + p)^n > (n k)p^k

       where (n k) is permutations (n * (n-1) * (n - 2) ... (n - k + 1))/k!

       so (n k) p^k > (n^k/2^k) * (p^k / k!)
       so if we take reciprocals of everything :
       0 < n^alpha / (1 + p)^n < (2^k k!) / (p^k)  * (n^(alpha - k))
       where the RHS is some constant times a decreasing sequence (n^(alpha
       -k))

       therefore by the squeeze theorem we get it.

    5. Also binomial theorem!

** Series - sequence with recursion.
   Some summation that forms a sequence of partial sums.
   s_n = sum (from k = 1 to n) a_k
   so form s_n+1 = s_n + a_n+1

   challenge - knowing a_n, understand s_n.

   we say that the sum converges if lim (n -> inf) s_n in RR

*** Cauchy Criterion
    The summation sum (n from 1 to inf) a_n converges if the series of partial
    sums {s_n} is convergent, namely given epsilon > 0, exists N s.t.

    m > n geq N -> abs(s_m - s_n) < epsilon.

    put another way, abs(sum (k = n+1 to m) a_k) < epsilon.
    in particular, pick some m = n + 1; then abs(a_{n+1}) < epsilon.
    or lim (n to infinity) a_n = 0. (recall that the converse is not true.)

*** Monotone convergence theorem
    Assume that s_n is monotonically increasing. so s_n+1 geq s_n for a_n geq 0.

    Then sum (from k = 1 to infinity) a_k convergent iff the partial sums are
    bounded.

*** Alternating Series Test
    if the terms alternate in sign and the a_n goes to zero, and abs(a_n)
    monotone, then the summation converges.

*** Comparison Test
    If abs(a_n) leq b_n and sum (from n = 1 to inf) b_n converges then sum
    (from n = 1 to inf) a_n converges.

**** Proof - two-step tango
     step 1 : show that the summation of abs(a_n) converges by showing some t_n
     = partial sums of a_k is bounded.

     Note that by definition sum abs(a_k) leq sum b_k < inf (termwise, finite)
     Therefore by the monotone convergence theorem -> the summation abs(a_k)
     converges (the sequence of partial sums is monotone, each non-negative)

     step 2 : show that the summation of abs(a_k) convergent -> summation of
     a_k converges. (absolute converge -> convergence)

     Trick - use Cauchy. abs(s_n - s_m) = abs(sum (from k=n+1 to m) a_k) <
     epsilon. THen

     abs(sum (from n+1 to m) a_k) leq sum (from k=n+1 to m) abs(a_k) < epsilon
     for m > n geq N(epsilon)
     as {t_n} is Cauchy -> done.

*** Convergence and Absolute Convergence

